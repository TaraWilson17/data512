{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Bias in data\n",
    "### Data 512\n",
    "### Saturday, October 5\n",
    "### Tara Wilson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook is created using [Python version 3.7](https://www.python.org/downloads/release/python-370/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I will import the necessary libraries to run the code. The following libraries are used:\n",
    "\n",
    "[pandas](https://pandas.pydata.org/)    \n",
    "[json](https://docs.python.org/3/library/json.html)  \n",
    "[requests](https://realpython.com/python-requests/)  \n",
    "[logging](https://docs.python.org/3/library/logging.html)  \n",
    "[numpy](https://numpy.org/)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import logging\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will set up a logging file to keep track of messages later in the file. I set the logging `level` to `INFO` since we want to track information and not error messages or other types of alerts. I set `format` to `%(message)s` so the message is printed out simply as a string. I set the `filename` to `bias_in_data_error_log.log` so the log will be saved with this title in the current working directory. Finally, I set the `filemode` to `w` for write permissions so that the file is re-written each time and not added on to since I do not need to keep historical logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(message)s',\n",
    "                    filename='bias_in_data_error_log.log',\n",
    "                    filemode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will then read in the 2 source files from the `source_data` folder into pandas DataFrames using the `read_csv` function:\n",
    "* page_data.csv\n",
    "* WPDS_2018_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_data = pd.read_csv(\"source_data/page_data.csv\")\n",
    "population_data = pd.read_csv(\"source_data/WPDS_2018_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will then take a look to ensure the data files are read in properly.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page dataframe row count:  47197\n"
     ]
    }
   ],
   "source": [
    "print(\"Page dataframe row count: \", page_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will also preview the dataset to ensure the columns are as we expect: \n",
    "* page (article names)\n",
    "* country\n",
    "* rev_id (revision ID for the article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>country</th>\n",
       "      <th>rev_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Template:ZambiaProvincialMinisters</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>235107991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bir I of Kanem</td>\n",
       "      <td>Chad</td>\n",
       "      <td>355319463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Template:Zimbabwe-politician-stub</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>391862046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Template:Uganda-politician-stub</td>\n",
       "      <td>Uganda</td>\n",
       "      <td>391862070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Template:Namibia-politician-stub</td>\n",
       "      <td>Namibia</td>\n",
       "      <td>391862409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 page   country     rev_id\n",
       "0  Template:ZambiaProvincialMinisters    Zambia  235107991\n",
       "1                      Bir I of Kanem      Chad  355319463\n",
       "2   Template:Zimbabwe-politician-stub  Zimbabwe  391862046\n",
       "3     Template:Uganda-politician-stub    Uganda  391862070\n",
       "4    Template:Namibia-politician-stub   Namibia  391862409"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population dataframe row count:  207\n"
     ]
    }
   ],
   "source": [
    "print(\"Population dataframe row count: \", population_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will also preview the population dataset to ensure the columns are as follows: \n",
    "* Geogrpahy\n",
    "* Population mid-2018 (millions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geography</th>\n",
       "      <th>Population mid-2018 (millions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>1,284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>42.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Egypt</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Libya</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Morocco</td>\n",
       "      <td>35.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Geography Population mid-2018 (millions)\n",
       "0    AFRICA                          1,284\n",
       "1   Algeria                           42.7\n",
       "2     Egypt                             97\n",
       "3     Libya                            6.5\n",
       "4   Morocco                           35.2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows with article page names that begin with the string \"Template\" need to be filtered out of `page_data` as these are not Wikipedia articles and we do not want to include them in the anlysis. To do so we will use Python's `~` operator described in detail [here](https://stackoverflow.com/questions/8305199/the-tilde-operator-in-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_data = page_data[~page_data[\"page\"].str.startswith(\"Template\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will next generate a `population_for_regions` DataFrame to track region level data for use later in the analysis. I loop through the population data grabbing all of the `Geography` column values that represent regions, denoted by all capital letters. I then save the name of the region and corresponding population to be used later. I also add the corresponding region to the `population_data` DataFrame for use in the analysis portion later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_for_regions = pd.DataFrame()\n",
    "\n",
    "# starting value for region, allows scope for variable outside of if statement\n",
    "region = \"\"\n",
    "\n",
    "regions = []\n",
    "region_pop = []\n",
    "region_name= []\n",
    "\n",
    "for index, row in population_data.iterrows():\n",
    "    # all upercase words are the region names\n",
    "    if row[\"Geography\"].isupper():\n",
    "        region = row[\"Geography\"]\n",
    "        region_pop.append(row[\"Population mid-2018 (millions)\"])\n",
    "        region_name.append(region)\n",
    "    regions.append(region)\n",
    "\n",
    "# append columns to existing DataFrames\n",
    "population_data[\"regions\"] = regions\n",
    "population_for_regions[\"region\"] = region_name\n",
    "population_for_regions[\"population\"] = region_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can preview the results of this loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>1,284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NORTHERN AMERICA</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LATIN AMERICA AND THE CARIBBEAN</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASIA</td>\n",
       "      <td>4,536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EUROPE</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            region population\n",
       "0                           AFRICA      1,284\n",
       "1                 NORTHERN AMERICA        365\n",
       "2  LATIN AMERICA AND THE CARIBBEAN        649\n",
       "3                             ASIA      4,536\n",
       "4                           EUROPE        746"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population_for_regions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The flat file data sources are now all properly read-in and prepared for the next step: gathering the article quality scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next step I will gather the quality data for each of the Wikipedia articles included in `page_data`. This data is sourced from the Objective Revision Evaluation Service [(ORES)](https://www.mediawiki.org/wiki/ORES) which provides a predicted label to represent the quality of the article. The available labels are:\n",
    "\n",
    "1. FA (Featured article)\n",
    "2. GA (Good article)\n",
    "3. B (B-class article)\n",
    "4. C (C-class article)\n",
    "5. Start (Start-class article)\n",
    "6. Stub (Stub-class article)\n",
    "\n",
    "where 1 is the highest quality and 6 is the lowest quality classification.\n",
    "\n",
    "I was unable to `pip install ores` so I am using the ORES API service to get the article quality predictions. The following code writes a function to and makes requests to the [REST API endpoint](https://ores.wikimedia.org/v3/#!/scoring/get_v3_scores_context_revid_model): `https://ores.wikimedia.org/v3/scores/{project}/?models={model}&revids={revids}`. The API requires the following parameters:\n",
    "\n",
    "| parameter | value |\n",
    "| ---------|:-----:|\n",
    "|*project*|`enwiki`|\n",
    "|*model*|`wp10`|\n",
    "|*revids*|List of revision IDs from `page_data`|\n",
    "\n",
    "\n",
    "The resulting API response will look something like:\n",
    "```json\n",
    "{'articlequality': \n",
    "    {'score': \n",
    "        {'prediction': B, \n",
    "         'probability': \n",
    "            {'GA': 0.005565225912988614, \n",
    "             'Stub': 0.285072978841463, \n",
    "             'C': 0.1237249061020009, \n",
    "             'B': 0.2910788689339172, \n",
    "             'Start': 0.2859984921969326, \n",
    "             'FA': 0.008559528012697881\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "The following function is adapted from [this example](https://github.com/Ironholds/data-512-a2/blob/master/hcds-a2-bias_demo.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ores_data(revision_ids):\n",
    "    \"\"\"\n",
    "    This function makes a request to the ORES API Endpoint. \n",
    "    Inputs:\n",
    "        - revision_ids: A list of revision IDs for Wikipedia articles\n",
    "    Outputs:\n",
    "        - A JSON object with the predicted quality for all revision IDs\n",
    "    \"\"\"\n",
    "    headers = {'User-Agent' : 'https://github.com/TaraWilson17', 'From' : 'wwtara@uw.edu'}\n",
    "    endpoint = 'https://ores.wikimedia.org/v3/scores/{project}/?models={model}&revids={revids}'\n",
    "    params = {'project' : 'enwiki',\n",
    "              'model'   : 'wp10',\n",
    "              'revids'  : '|'.join(str(x) for x in revision_ids)\n",
    "              }\n",
    "    api_call = requests.get(endpoint.format(**params))\n",
    "    response = api_call.json()\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid overloading the API, I batched the requests in groups of 50 as recommended by the documentation. For each batch, I grab the array of JSON responses. I then try to parse the prediction from the response. If this is successful, I add the article and the corresponding prediction to the lists. If this is unsuccessful, the revision ID is logged to the file created at the top of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "revision_id = []\n",
    "article_quality = []\n",
    "\n",
    "# converts `rev_id` column to integer data type\n",
    "page_data[\"rev_id\"] = page_data[\"rev_id\"].astype(np.int64)\n",
    "\n",
    "# loops through all data, 50 rows at a time\n",
    "for i in range(0, page_data.shape[0], 50):\n",
    "    # calls my get_ores_data function above with list of rev id's passed in\n",
    "    ores_responses = get_ores_data(np.array(page_data[\"rev_id\"].iloc[i:i + 50,]))\n",
    "    for article in ores_responses[\"enwiki\"][\"scores\"]:\n",
    "        try:\n",
    "            # saves prediction if it exists\n",
    "            article_quality.append(ores_responses[\"enwiki\"][\"scores\"][article][\"wp10\"][\"score\"][\"prediction\"])\n",
    "        except:\n",
    "            logging.info(\"Unable to get a ORES response for revision id: %s\", article)\n",
    "        else:\n",
    "            revision_id.append(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will create a dataframe, `article_data`, that stores the results from the ORES API calls. It has a column for the revision IDs and another for the article quality prediction from ORES. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data = pd.DataFrame()\n",
    "article_data[\"revision_id\"] = revision_id\n",
    "article_data[\"article_quality\"] = article_quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will then convert the `revision_id` column into an integer datatype and then merge the `article_data` DataFrame with the `page_data` from above with the article names, corresponding revision ID and the country the article references. We can join the columns by the revision ID respective columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts revision_ids to be of integer type\n",
    "article_data[\"revision_id\"] = article_data[\"revision_id\"].astype(str).astype(int)\n",
    "\n",
    "# renames columns to proper names and to match between datasets\n",
    "page_data = page_data.rename(columns={\"rev_id\": \"revision_id\"})\n",
    "page_data = page_data.rename(columns={\"page\": \"article_name\"})\n",
    "\n",
    "all_article_data = pd.merge(article_data, page_data, on=\"revision_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will then merge the above dataset with the `population_data` from above to bring in the population data for all of the countries. I will join on `country` from the article dataset above with the renamed `Geography` column in the population source data. Pandas `merge` function takes an argument,`indicator=True` to allow rows to include documentation on the source of the data on an outer join where some sources may have been null. Data without matches, denoted by markers other than `both` in the merge indicator column, are saved to a seperate DataFrame named `no_match_data`. Data with the merge indicator set to `both` will be saved to the `all_data` DataFrame. I will then preview this resulting dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revision_id</th>\n",
       "      <th>article_quality</th>\n",
       "      <th>article_name</th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>regions</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>355319463.0</td>\n",
       "      <td>Stub</td>\n",
       "      <td>Bir I of Kanem</td>\n",
       "      <td>Chad</td>\n",
       "      <td>15.4</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>498683267.0</td>\n",
       "      <td>Stub</td>\n",
       "      <td>Abdullah II of Kanem</td>\n",
       "      <td>Chad</td>\n",
       "      <td>15.4</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>565745353.0</td>\n",
       "      <td>Stub</td>\n",
       "      <td>Salmama II of Kanem</td>\n",
       "      <td>Chad</td>\n",
       "      <td>15.4</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>565745365.0</td>\n",
       "      <td>Stub</td>\n",
       "      <td>Kuri I of Kanem</td>\n",
       "      <td>Chad</td>\n",
       "      <td>15.4</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>565745375.0</td>\n",
       "      <td>Stub</td>\n",
       "      <td>Mohammed I of Kanem</td>\n",
       "      <td>Chad</td>\n",
       "      <td>15.4</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   revision_id article_quality          article_name country population  \\\n",
       "0  355319463.0            Stub        Bir I of Kanem    Chad       15.4   \n",
       "1  498683267.0            Stub  Abdullah II of Kanem    Chad       15.4   \n",
       "2  565745353.0            Stub   Salmama II of Kanem    Chad       15.4   \n",
       "3  565745365.0            Stub       Kuri I of Kanem    Chad       15.4   \n",
       "4  565745375.0            Stub   Mohammed I of Kanem    Chad       15.4   \n",
       "\n",
       "  regions _merge  \n",
       "0  AFRICA   both  \n",
       "1  AFRICA   both  \n",
       "2  AFRICA   both  \n",
       "3  AFRICA   both  \n",
       "4  AFRICA   both  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# renames columns to correct names and to match between datasets\n",
    "population_data = population_data.rename(columns={\"Geography\": \"country\"})\n",
    "population_data = population_data.rename(columns={\"Population mid-2018 (millions)\": \"population\"})\n",
    "\n",
    "# merges datasets on 'country' column, outer join\n",
    "all_data = pd.merge(all_article_data, population_data, on=\"country\", how=\"outer\", indicator=True)\n",
    "\n",
    "# selects data not represented in both datasets\n",
    "no_match_data = all_data[all_data[\"_merge\"] != \"both\"]\n",
    "all_data = all_data[all_data[\"_merge\"] == \"both\"]\n",
    "\n",
    "# preview data\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will write the resulting data to .csv using python's `to_csv` function. Both the matches and no matches csv files are saved to a folder named `output_data` inside the current working directory.\n",
    "\n",
    "Both files contain the following columns (the no_match data will have `None` values for at least one column in every row):\n",
    "* country\n",
    "* article_name\n",
    "* revision_id\n",
    "* article_quality\n",
    "* population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv(\"output_data/wp_wpds_politicians_by_country.csv\", sep=\",\", columns=[\"country\", \"article_name\", \"revision_id\", \"article_quality\", \"population\"])\n",
    "no_match_data.to_csv(\"output_data/wp_wpds_countries-no_match.csv\", sep=\",\", columns=[\"country\", \"article_name\", \"revision_id\", \"article_quality\", \"population\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to complete some analysis on the resulting dataset. This will allow me to derive some metrics to generate some summary statistics for different countries.  \n",
    "\n",
    "The first step is to create a DataFrame to store the computed columns. I then loop through all of the unique countries in the data and make calculations. First, I gather all of the data in the `all_data` DataFrame, the result of the above merge, and filter by only rows with the country name for that loop iteration. To get the counts of articles from that country, I can simply get the `len()` of the rows meeting this condition, as each row in the dataset represents a unique article. High quality articles are defined as those with a prediction of `GA` or `FA`. I then loop through all of the filtered rows and increment a counter variable for each article that is either `GA` or `FA` quality. Once all the rows in the filtered dataset have been processed, I save this count of high quality articles. I then append the population of the country to the dataset as well to use in later calculations. Finally, I merge all of these calculations into the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_stats = pd.DataFrame()\n",
    "country_list = []\n",
    "counts = []\n",
    "populations= []\n",
    "high_quality_counts = []\n",
    "\n",
    "# gets list of all countries included at least once in all_data\n",
    "countries = all_data[\"country\"].unique()\n",
    "\n",
    "for country in countries:\n",
    "    country_list.append(country)\n",
    "    # filter by current selected country\n",
    "    articles_from_country = all_data[all_data[\"country\"] == country]\n",
    "    counts.append(len(articles_from_country))\n",
    "    count = 0\n",
    "    for index, row in articles_from_country.iterrows():\n",
    "        # \"FA\" and \"GA\" are considered 'high quality' predictions\n",
    "        if row[\"article_quality\"] == \"FA\" or row[\"article_quality\"] == \"GA\":\n",
    "            count += 1\n",
    "    high_quality_counts.append(count)\n",
    "    populations.append(row[\"population\"])\n",
    "    \n",
    "    \n",
    "article_stats[\"country\"] = country_list\n",
    "article_stats[\"num_articles\"] = counts\n",
    "article_stats[\"population\"] = populations\n",
    "article_stats[\"num_high_quality_articles\"] = high_quality_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can preview the resulting statistical dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>num_articles</th>\n",
       "      <th>population</th>\n",
       "      <th>num_high_quality_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chad</td>\n",
       "      <td>97</td>\n",
       "      <td>15.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cambodia</td>\n",
       "      <td>213</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Canada</td>\n",
       "      <td>843</td>\n",
       "      <td>37.2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Egypt</td>\n",
       "      <td>235</td>\n",
       "      <td>97</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>1023</td>\n",
       "      <td>200.6</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country  num_articles population  num_high_quality_articles\n",
       "0      Chad            97       15.4                          2\n",
       "1  Cambodia           213         16                          4\n",
       "2    Canada           843       37.2                         22\n",
       "3     Egypt           235         97                          9\n",
       "4  Pakistan          1023      200.6                         19"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I will repeat the process above but at a region level this time. All of the criteria and calculations at the region level are the same, with the exception of tracking the region population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_stats = pd.DataFrame()\n",
    "region_list = []\n",
    "num_articles = []\n",
    "high_quality_counts = []\n",
    "\n",
    "# gets list of all regions included at least once in all_data\n",
    "regions = all_data[\"regions\"].unique()    \n",
    "\n",
    "for region in regions:\n",
    "    region_list.append(region)\n",
    "    # filters data to rows with current selected region\n",
    "    articles_from_region = all_data[all_data[\"regions\"] == region]\n",
    "    num_articles.append(len(articles_from_region))\n",
    "    count = 0\n",
    "    for index, row in articles_from_region.iterrows():\n",
    "        # \"FA\" and \"GA\" are considered 'high quality' predictions\n",
    "        if row[\"article_quality\"] == \"FA\" or row[\"article_quality\"] == \"GA\":\n",
    "            count += 1\n",
    "    high_quality_counts.append(count)\n",
    "    \n",
    "region_stats[\"region\"] = region_list\n",
    "region_stats[\"num_articles\"] = num_articles\n",
    "region_stats[\"num_high_quality_articles\"] = high_quality_counts   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To gather population data at a region level, I will merge the DataFrame just created with the `population_for_regions` DataFrame created earlier in this notebook. I will join these two sources on the `region` column. Again, I can preview the region statistics DataFrame to ensure everything looks correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>num_articles</th>\n",
       "      <th>num_high_quality_articles</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>6851</td>\n",
       "      <td>125</td>\n",
       "      <td>1,284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASIA</td>\n",
       "      <td>11531</td>\n",
       "      <td>310</td>\n",
       "      <td>4,536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NORTHERN AMERICA</td>\n",
       "      <td>1921</td>\n",
       "      <td>99</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EUROPE</td>\n",
       "      <td>15864</td>\n",
       "      <td>322</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LATIN AMERICA AND THE CARIBBEAN</td>\n",
       "      <td>5169</td>\n",
       "      <td>69</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            region  num_articles  num_high_quality_articles  \\\n",
       "0                           AFRICA          6851                        125   \n",
       "1                             ASIA         11531                        310   \n",
       "2                 NORTHERN AMERICA          1921                         99   \n",
       "3                           EUROPE         15864                        322   \n",
       "4  LATIN AMERICA AND THE CARIBBEAN          5169                         69   \n",
       "\n",
       "  population  \n",
       "0      1,284  \n",
       "1      4,536  \n",
       "2        365  \n",
       "3        746  \n",
       "4        649  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_stats = pd.merge(region_stats, population_for_regions, on=\"region\")\n",
    "region_stats.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will do some data cleaning to allow for calculations below. The `population` data is reported in millions, so I will conert the column to string data type and replace the `,`'s found in the data, for example: population 1,174 M. I then convert these to floats and multiply them by 1,000,000 to accurately represent the population in millions for calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populations reported in millions\n",
    "article_stats[\"population\"] = article_stats[\"population\"].str.replace(\",\",\"\")\n",
    "article_stats[\"population\"] = article_stats[\"population\"].astype(float) * 1000000\n",
    "\n",
    "region_stats[\"population\"] = region_stats[\"population\"].str.replace(\",\",\"\")\n",
    "region_stats[\"population\"] = region_stats[\"population\"].astype(float) * 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will do some feature engineering where I calculate the proportion of total articles per population, as well as the number of high quality articles (labled `GA` or `FA` by ORES) per total number of articles. I do this for both the `article_stats` DataFrame at a country level and the `region_stats` DataFrame at a geographic region level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_stats[\"articles_per_population\"] = article_stats[\"num_articles\"] / article_stats[\"population\"]\n",
    "article_stats[\"quality_articles_per_articles\"] = article_stats[\"num_high_quality_articles\"] / article_stats[\"num_articles\"]\n",
    "\n",
    "region_stats[\"articles_per_population\"] = region_stats[\"num_articles\"] / region_stats[\"population\"]\n",
    "region_stats[\"quality_articles_per_articles\"] = region_stats[\"num_high_quality_articles\"] / region_stats[\"num_articles\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the aggregated dataset and calculated columns, I will generate some result tables to explore the findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Top 10 countries by coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the 10 countries with the highest proportion of politician articles on Wikideia per the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>articles_per_population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>0.005400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Nauru</td>\n",
       "      <td>0.005200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>San Marino</td>\n",
       "      <td>0.002700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Monaco</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Liechtenstein</td>\n",
       "      <td>0.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Tonga</td>\n",
       "      <td>0.000630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Marshall Islands</td>\n",
       "      <td>0.000617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>0.000503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>0.000425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Grenada</td>\n",
       "      <td>0.000360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              country  articles_per_population\n",
       "98             Tuvalu                 0.005400\n",
       "149             Nauru                 0.005200\n",
       "39         San Marino                 0.002700\n",
       "63             Monaco                 0.001000\n",
       "97      Liechtenstein                 0.000700\n",
       "86              Tonga                 0.000630\n",
       "104  Marshall Islands                 0.000617\n",
       "66            Iceland                 0.000503\n",
       "166           Andorra                 0.000425\n",
       "77            Grenada                 0.000360"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_by_coverage = article_stats.nlargest(10, \"articles_per_population\")\n",
    "top_10_by_coverage[[\"country\", \"articles_per_population\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bottom 10 countries by coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the 10 countries with the least amount of politician articles on Wikideia per the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>articles_per_population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>India</td>\n",
       "      <td>7.146503e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Indonesia</td>\n",
       "      <td>7.918552e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>China</td>\n",
       "      <td>8.107332e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>8.510638e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>9.395349e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Korea, North</td>\n",
       "      <td>1.406250e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>1.412429e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>1.691843e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Mozambique</td>\n",
       "      <td>1.901639e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>1.917067e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          country  articles_per_population\n",
       "6           India             7.146503e-07\n",
       "58      Indonesia             7.918552e-07\n",
       "20          China             8.107332e-07\n",
       "150    Uzbekistan             8.510638e-07\n",
       "106      Ethiopia             9.395349e-07\n",
       "163  Korea, North             1.406250e-06\n",
       "178        Zambia             1.412429e-06\n",
       "126      Thailand             1.691843e-06\n",
       "125    Mozambique             1.901639e-06\n",
       "115    Bangladesh             1.917067e-06"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_10_by_coverage = article_stats.nsmallest(10, \"articles_per_population\")\n",
    "bottom_10_by_coverage[[\"country\", \"articles_per_population\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Top 10 countries by relative quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the 10 countries with the highest proportion of quality articles (`GA` or `FA` predictions from ORES) per number of politician articles on Wikipedia from that country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>quality_articles_per_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Korea, North</td>\n",
       "      <td>0.194444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>0.127119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Mauritania</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Central African Republic</td>\n",
       "      <td>0.121212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Romania</td>\n",
       "      <td>0.113703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>0.092593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Bhutan</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Dominica</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Syria</td>\n",
       "      <td>0.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Benin</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      country  quality_articles_per_articles\n",
       "163              Korea, North                       0.194444\n",
       "169              Saudi Arabia                       0.127119\n",
       "138                Mauritania                       0.125000\n",
       "161  Central African Republic                       0.121212\n",
       "45                    Romania                       0.113703\n",
       "98                     Tuvalu                       0.092593\n",
       "124                    Bhutan                       0.090909\n",
       "172                  Dominica                       0.083333\n",
       "47                      Syria                       0.078125\n",
       "44                      Benin                       0.076923"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_by_quality = article_stats.nlargest(10, \"quality_articles_per_articles\")\n",
    "top_10_by_quality[[\"country\", \"quality_articles_per_articles\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Bottom 10 countries by relative quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the 10 countries with the least number of quality articles (`GA` or `FA` predictions from ORES) per number of politician articles on Wikipedia from that country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>quality_articles_per_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Malta</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Angola</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Finland</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Tunisia</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>San Marino</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Uganda</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Moldova</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Monaco</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Turkmenistan</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Slovakia</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         country  quality_articles_per_articles\n",
       "14         Malta                            0.0\n",
       "22        Angola                            0.0\n",
       "28       Finland                            0.0\n",
       "32       Tunisia                            0.0\n",
       "39    San Marino                            0.0\n",
       "50        Uganda                            0.0\n",
       "52       Moldova                            0.0\n",
       "63        Monaco                            0.0\n",
       "76  Turkmenistan                            0.0\n",
       "80      Slovakia                            0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_10_by_quality = article_stats.nsmallest(10, \"quality_articles_per_articles\")\n",
    "bottom_10_by_quality[[\"country\", \"quality_articles_per_articles\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Geographic regions by coverage (by politician articles from countries in each region as a proportion of total regional population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The geographic regions in order of most politician articles per population to least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>articles_per_population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OCEANIA</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EUROPE</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LATIN AMERICA AND THE CARIBBEAN</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NORTHERN AMERICA</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASIA</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            region  articles_per_population\n",
       "5                          OCEANIA                 0.000076\n",
       "3                           EUROPE                 0.000021\n",
       "4  LATIN AMERICA AND THE CARIBBEAN                 0.000008\n",
       "0                           AFRICA                 0.000005\n",
       "2                 NORTHERN AMERICA                 0.000005\n",
       "1                             ASIA                 0.000003"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_by_coverage = region_stats.sort_values(\"articles_per_population\", ascending=False)\n",
    "regions_by_coverage[[\"region\", \"articles_per_population\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Geographic regions by coverage (by relative proportion of politician articles from countries in each region that are of GA and FA-quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The geographic regions in order of highest proportion of high quality articles to total articles to least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>quality_articles_per_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NORTHERN AMERICA</td>\n",
       "      <td>0.051536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASIA</td>\n",
       "      <td>0.026884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OCEANIA</td>\n",
       "      <td>0.021100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EUROPE</td>\n",
       "      <td>0.020298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>0.018246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LATIN AMERICA AND THE CARIBBEAN</td>\n",
       "      <td>0.013349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            region  quality_articles_per_articles\n",
       "2                 NORTHERN AMERICA                       0.051536\n",
       "1                             ASIA                       0.026884\n",
       "5                          OCEANIA                       0.021100\n",
       "3                           EUROPE                       0.020298\n",
       "0                           AFRICA                       0.018246\n",
       "4  LATIN AMERICA AND THE CARIBBEAN                       0.013349"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_by_quality_coverage = region_stats.sort_values(\"quality_articles_per_articles\", ascending=False)\n",
    "regions_by_quality_coverage[[\"region\", \"quality_articles_per_articles\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflections and implications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write a few paragraphs reflecting on what you have learned, what you found, what (if anything) surprised you about your findings, and/or what theories you have about why any biases might exist (if you find they exist). You can also include any questions this assignment raised for you about bias, Wikipedia, or machine learning.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I learned a lot during the process of this assignment. First, I strengthened my technical skills as I had not done much data source merging before this assignment. Ideas such as logging which rows I could not get data for or saving rows from a merge that don't match were not concepts I was previously familiar with. \n",
    "\n",
    "As I expected, population was a huge driver in the relative proportions of articles analysis. Less people likely means less politicians and less articles but this relationship is likely not directly linear. It is difficult to quantify this relationship by looking at the data used for the table calculations as there are likely other factors. I believe this cold be a source of 'bias' of sorts introduced into the analysis.\n",
    "\n",
    "There are many cases where bias could exist which are discussed more below. Additionally, there are many edge cases where the data represented here may not tell the store. For example, data censorship and government control are likely what lead to North Korea landing low on article count per population but high on the quality list. This is an interesting case where the government influences much more about what is communicated than in other nations. I believe this could cause bias since it sways these numbers in a way not accounted for by a data field.\n",
    "\n",
    "Following our Wikipedia 'attack' recognition exercise in class on Week 3, it became very clear that there is no clear consensus on content in this papers even in extremes like personal attacks. Depending on how the data used to train the ORES model was labeled, this could be a significant source of bias in this dataset, especially if those in charge of the classification were not a representative sample.\n",
    "\n",
    "This assignment made me wonder as a whole how much the training data effects the model, e.g. if a model was train on a disproportionate sample of quality articles, would it be more likely to make the prediction equal to whatever was most heavily represented in the training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What biases did you expect to find in the data (before you started working with it), and why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I expected the data to be biased by representation. Since this analysis is based on Wikipedia articles, countries with less internet access and less of a norm around digital news will be underrepresented in this dataset. Additionally, depending on how government is structured in a certain country there may be more or less articles regarding politicians. \n",
    "\n",
    "When we looked at the Wikipedia contribution maps in class the distributions were not as I expected. Such as I believe the most contributions written in Mandarin were from France since Wikipedia is banned in China. When dealing with political articles this could really influence the quantity, and quality, of articles. \n",
    "\n",
    "There are several [countries where Wikipedia is banned](https://en.wikipedia.org/wiki/Censorship_of_Wikipedia).  China, where Wikipedia is banned, and Uzbekistan, where Wikipedia is censored, both show up on the bottom 10 by coverage list as we might expect. For a more detailed analysis, it may be worth considering factors such as this in the conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What (potential) sources of bias did you discover in the course of your data processing and analysis?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ORES service is designed to address the quality of Wikipedia articles in a manner that is scalable. To do so, it must rely on many assumptions that may unintentionally introduce bias into the analysis. \n",
    "\n",
    "The ORES service leverages identifications of articles that might need to be deleted. The [documentation page](mediawiki.org/wiki/ORES) lists the models used for detection of vandalism, attacks or spam of English writings. The page then states that articles that pass this initial test have their quality examined based on the [English Wikipedia 1.0 assessment rating scale](en.wikipedia.org/wiki/Wikipedia:Version_1.0_Editorial_Team). I could only find mentions of the English models used on the documentation page. It is then unclear if there are comparable models for other languages or how this was addressed as likely the international dataset represented much more than the English language. Even if articles were all translated to English prior to analysis, there is likely to be some issues in translation. Therefore, articles written in a non-English language may be more or less likely to be flagged as a 'delete' article, skewing the representation of the dataset. \n",
    "\n",
    "The ORES predictive learning model is [based on human assessment](mediawiki.org/wiki/ORES). As we discussed in class, humans can make errors in labeling so there is a ceiling on the model performance that is likely not 100% correct. This can introduce subtle bias in terms of what the human was most likely to flag an article as.\n",
    "\n",
    "The article quality model is [based on the structure of the article](mediawiki.org/wiki/ORES). It looks at certain characteristics such as the sections, references, citation format but does not look at \"the quality of the writing or whether or not there's a tone problem,\" instead claiming that many \"structural characteristics of articles seem to correlate strongly with good writing and tone.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Can you think of a realistic data science research situation where using these data (to train a model, perform a hypothesis-driven research, or make business decisions) might create biased or misleading results, due to the inherent gaps and limitations of the data?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the ORES responses are based on the structure of the article as mentioned above, I can see some serious potential bias issues here. For example, in countries where there is less formal education around writing formatting, articles from that area may consistently score lower on the ORES rankings. While it has been seen that there is a strong correltion between structure and an article's writing and tone, this relationship is not guarenteed. A well-written piece with a non-traditional structure may score poorly when in face the article had high quality content. This could be a case where the results may be unintentionally biased.\n",
    "\n",
    "Additionally, I am not sure what the relationship is between population and number of politicians. For example, if 2 countries both have 10M population but Country A has a government made of 500 politicians and Country B has a government with just 100 politicians, I would expect there to be variation in terms of thier respective number of articles. Therefore, it may be interesting to include a variable of government size in this analysis and see how well this was tied to population. Depending on the desired conclusions, this could sway the results.\n",
    "\n",
    "Data will never be perfectly clear and unbiased. This data analysis, like most, is ripe for bias and misinterpretation. Therefore, considering factors mentioned above such as Wikipedia censorship will al"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
